{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import sin\n",
    "from numpy import pi\n",
    "from numpy import cos\n",
    "from numpy import exp\n",
    "from numpy import tanh\n",
    "from numpy import zeros\n",
    "from numpy import arccos\n",
    "from numpy import log10\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import emcee\n",
    "from pylab import plot\n",
    "from scipy import integrate\n",
    "import corner\n",
    "import random\n",
    "from collections import Counter\n",
    "import time\n",
    "import scipy\n",
    "from scipy.stats import poisson # use as poisson.pmf(number of events , mean value)\n",
    "from scipy import optimize\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value\n",
    "from tqdm import *\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "from astropy import constants as const\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cmasher as cmr\n",
    "import matplotlib.colors as clrs\n",
    "import matplotlib.cm as cmap\n",
    "\n",
    "colors = ['#8a1f1f','#79a43a','#C59D34','#171782', '#cf6717','#ad6faa',\n",
    "          '#009999','#828282']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=colors)\n",
    "plt.rcParams['lines.linewidth'] = 3.0\n",
    "plt.rcParams['axes.linewidth'] = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath\n",
    "# we work in geometrized units\n",
    "Msol = 1.47680000000000000000000000000000000 # in km\n",
    "c = 1 # we have actually put them to one everywhere in the code already\n",
    "G = 1\n",
    "year = 60*60*24*(365.250000000000000000000000000); # s\n",
    "cc = 2.9980000000000000000000000000000*10**5 # velocity of light in Km/s\n",
    "pc = 3.0856770000000000000000000000*10**13 # km\n",
    "\n",
    "H0 = 67.9 # km /s / Mpc # changed to PLANCK 2015\n",
    "Omegam = 0.306\n",
    "OmegaL = 0.694\n",
    "Omegar = 0.\n",
    "\n",
    "# some useful functions \n",
    "def distL(z):\n",
    "    return (1+z) * integrate.quad(invE,0,z)[0] *cc / H0 *10**6*pc # km\n",
    "\n",
    "def Ez(z):\n",
    "    return sqrt(Omegar*(1+z)**4+Omegam*(1+z)**3+OmegaL)\n",
    "\n",
    "def invE(z):\n",
    "    return 1. / Ez(z)\n",
    "\n",
    "def primopezzo(zp):\n",
    "    return 1/Ez(zp)*(integrate.quad(invE,0,zp)[0])**2\n",
    "\n",
    "def dVdz(z):\n",
    "    return 4*pi*(cc/H0)**3*primopezzo(z) # Mpc**3\n",
    "\n",
    "def dtdf(f,m1,m2):  # Hz, km, km, gravitational wave frequency\n",
    "    return 5/(96*pi**(8/3))*(1./cc*(m1 + m2)*(m1*m2/(m1 + m2)**2)**(3/5))**(-5/\n",
    "  3)*f**(-11/3)  # s^2, assuming f in Hz and m in km\n",
    "\n",
    "def solof(f):\n",
    "    return f**(-11/3)\n",
    "\n",
    "def nu(m1,m2):\n",
    "    return m1*m2/((m1+m2)**2)\n",
    "\n",
    "def Mc(m1,m2):\n",
    "    return (m1 + m2) * (m1*m2/((m1+m2)**2))**(3/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other useful functions for frequencies, time of merger, ecc \n",
    "\n",
    "# frequency functions \n",
    "\n",
    "def fMIN2(fmax0,m1,m2,Tobs): # gravitational wave frequency\n",
    "    return 1/(1/fmax0**(8/3)+256/5*(Mc(m1,m2)/cc)**(5/3)*pi**(8/3)*(Tobs))**(3/8)\n",
    "\n",
    "def fmax(m1,m2,fmin,Tobs): # gravitational wave frequency\n",
    "    return fmin*((5*cc)/(5*cc-256*fmin**(8/3)*pi**(8/3)*Tobs*Mc(m1,m2)*(Mc(m1,m2)/cc)**(2/3)))**(3/8)\n",
    "\n",
    "\n",
    "# gives fmax, given fmin and Tobs. If fmax is above 10 Hz, gives 10 Hz instead. frequency is always in Hz\n",
    "\n",
    "def getfmax(m1,m2,fmin,Tobs): # gravitational wave frequency\n",
    "    if fMIN2(1,m1,m2,Tobs)>fmin:\n",
    "        return fmax(m1,m2,fmin,Tobs)\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "def Tmerger(m1,m2,fmin): # gravitational wave frequency\n",
    "    return 5. * (m1 + m2)**(1./3.) * cc**(5./3.)/ (256. * fmin**(8./3.) * m1 * m2 * np.pi**(8./3.))\n",
    "\n",
    "\n",
    "\n",
    "from scipy.optimize import root_scalar\n",
    "def findFmin(timemerger,m1,m2):\n",
    "    def condition(fmin):\n",
    "        return timemerger-Tmerger(m1,m2,fmin)\n",
    "    return root_scalar(condition,bracket=(10**-4,1)).root\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9679201698698369"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findFmin(0.001 * year, 10 ,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we want to add also the part with the SNR \n",
    "\n",
    "# LISA noise parameters\n",
    "Amp = 5/10*18/10*10**-44\n",
    "alpha = 138/1000\n",
    "beta = -221\n",
    "kappa = 521\n",
    "gamma = 1680\n",
    "fk = 113/10**5\n",
    "L0 = 25/10*10**9\n",
    "fstar = 1909/100*10**-3\n",
    "pm = 10**-12\n",
    "\n",
    "skyav=(4/5*sqrt(2)*sin(pi/3))\n",
    "\n",
    "# noise function, checked with Mathematica\n",
    "\n",
    "def Sacc(f):\n",
    "    return (3*10**-15)**2*(1+(4/10*10**-3/f)**2)*(1+(f/(8*10**-3))**4)\n",
    "\n",
    "def Sgal(f):\n",
    "    return Amp*f**(-7/3)*exp(-f**alpha+beta*f*sin(kappa*f))*(1+tanh(gamma*(fk-f)))\n",
    "\n",
    "def Soms(f):\n",
    "    return (15. *pm)**2*(1+(2*10**-3/f)**4)  # noi: 10\n",
    "\n",
    "def Sacc(f):\n",
    "    return (3*10**-15)**2*(1+(4/10*10**-3/f)**2)*(1+(f/(8*10**-3))**4)\n",
    "    \n",
    "def SnSA(f):\n",
    "    return 10/3*(4*Sacc(f)/(2*pi*f)**4+Soms(f))/(L0**2)*(1+6/10*(f/fstar)**2)\n",
    "\n",
    "def R(f):\n",
    "    return 3/20*2\n",
    "\n",
    "def Sn(f):\n",
    "    return abs(SnSA(f)+Sgal(f))\n",
    "\n",
    "def Pn(f): # gravitational wave frequency\n",
    "    return abs(Sn(f)*R(f))\n",
    "\n",
    "def Aplus(iota,psi):\n",
    "    return -(1+cos(iota)**2)*cos(2*psi)-2*cos(iota)*sin(2*psi)\n",
    "\n",
    "def Across(iota,psi):\n",
    "    return (1+cos(iota)**2)*sin(2*psi)-2*cos(iota)*cos(2*psi)\n",
    "\n",
    "def Fplus(theta,phi):\n",
    "    return 1/2*(1+cos(theta)**2)*cos(2*phi)\n",
    "\n",
    "def Fcross(theta,phi):\n",
    "    return cos(theta)*sin(2*phi)\n",
    "\n",
    "def factorsky(iota,psi,theta,phi):\n",
    "    return Fplus(theta,phi)*Aplus(iota,psi)+1j*Fcross(theta,phi)*Across(iota,psi)\n",
    "\n",
    "def factorskySNR(iota,psi,theta,phi):\n",
    "    return abs(sqrt(2)*sin(pi/3)*(Fplus(theta,phi)*Aplus(iota,psi)+1j*Fcross(theta,phi)*Across(iota,psi)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform and SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform\n",
    "\n",
    "def ampl(m1,m2,d): \n",
    "    return (Mc(m1,m2)*G)**(5/6)*sqrt(5/24)/(pi**(2/3)*d*c**(3/2))\n",
    "def habs(m1,m2,d,f): # gravitational wave frequency\n",
    "    return ampl(m1,m2,d)*f**(-7/6)\n",
    "\n",
    "#print(habs(12.4913,12.3884,10.8287*10**6*pc,1./cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the SNR; \n",
    "# be careful that I have already put the factor for the sky average\n",
    "# we use the GW only template.\n",
    "\n",
    "def SNR(iota,psi,theta,phi,fmin,fmax,m1,m2,d): # gravitational wave frequency\n",
    "    return sqrt(4*integrate.quad(lambda x: (factorskySNR(iota,psi,theta,phi)*habs(m1,m2,d, x/cc))**2/(Pn(x)*(cc**2)), fmin, fmax)[0])\n",
    "#different noise here!\n",
    "\n",
    "def SNRAverage(fmin,fmax,m1,m2,d): # gravitational wave frequency\n",
    "    return sqrt(4*integrate.quad(lambda x: (skyav*habs(m1,m2,d, x/cc))**2/(Pn(x)*(cc**2)), fmin, fmax)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.07125245940824\n"
     ]
    }
   ],
   "source": [
    "z = 0.24716227944027847\n",
    "tmerger = 5.073762956477287*year\n",
    "m1 = 88.7\n",
    "m2 = 64.93\n",
    "(iota, psi, theta, phi) = 2.23353428920549, 5.484427462941964, 2.014813251983311, 2.374251372635906\n",
    "fmin = findFmin(tmerger,m1,m2)\n",
    "#print(fmin)\n",
    "tobs = 6.*year\n",
    "fmax= getfmax(m1*(1.+z),m2*(1.+z),fmin/(1+z),tobs)\n",
    "#print(fmax)\n",
    "loSNR=SNR(iota,psi,theta,phi,fmin/(1+z),fmax,m1*(1+z),m2*(1+z),distL(z))\n",
    "print(loSNR) # 6.155,9.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "eobdata = np.loadtxt('EOBmasses.dat')\n",
    "NRdata = np.loadtxt('NRmasses.dat')\n",
    "Phendata = np.loadtxt('PHENmasses.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data = h5py.File('/Users/andreacaputo/Desktop/Phd/BinaryLISALIGO/Event_SamplesWaveTransient/all_events/o1o2o3_mass_c_iid_mag_two_comp_iid_tilt_powerlaw_redshift_mass_data.h5', 'r')\n",
    "mass_ppd = data[\"ppd\"]\n",
    "mass_lines = data[\"lines\"]\n",
    "\n",
    "# Create a flat copy of the array\n",
    "flat = mass_ppd[:].flatten() /  np.sum(mass_ppd[:].flatten())\n",
    "\n",
    " \n",
    "mass_1 = np.linspace(3, 100, 1000)\n",
    "mass_ratio = np.linspace(0.1, 1, 500)\n",
    "\n",
    "ratePL = np.trapz(np.trapz(mass_ppd, mass_ratio, axis=0), mass_1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_ppd[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['mass_1', 'mass_ratio']>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines['mass_1'][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5166"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len(mass_lines['mass_ratio'][:]))\n",
    "try1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )\n",
    "flat = mass_ppd[:].flatten() /  np.sum(mass_ppd[:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "       1.53344045e-110, 7.08344558e-111, 3.26828825e-111])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 500)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines['mass_ratio'][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "massratioAll = mass_lines['mass_ratio'][:]\n",
    "mass1All = mass_lines['mass_1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij, ik -> jk', massratioAll , mass1All).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrNewGamma(N,iteration,massoption,SNRth, Tobs, duty):\n",
    "    \n",
    "\n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=50*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 0.512\n",
    "    zmin = 0.1\n",
    "    tmax = 40\n",
    "    tobs = Tobs # in years\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = distL(z)\n",
    "        \n",
    "        if massoption == 'EOB':\n",
    "            index = np.random.choice(len(eobdata))\n",
    "            m1 = Msol*eobdata[index][0]\n",
    "            m2 = Msol*eobdata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "        \n",
    "        if massoption == 'PHEN':\n",
    "            index = np.random.choice(len(Phendata))\n",
    "            m1 = Msol* Phendata[index][0]\n",
    "            m2 = Msol*Phendata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "            \n",
    "            \n",
    "        if massoption == 'NR':\n",
    "            index = np.random.choice(len(NRdata))\n",
    "            m1 = Msol*NRdata[index][0]\n",
    "            m2 = Msol*NRdata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "                \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(1*year,41*year)\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr=np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl)\n",
    "\n",
    "        dVcdz = cosmo.comoving_volume(z).value \n",
    "        rateSampling = np.random.gamma(1, 1.46*Rate) #np.random.normal(Rate, 0.3e-9)#1 / np.random.gamma(1, 1/ Rate)\n",
    "        \n",
    "        integralbulk = rateSampling * tmax * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * (1./(1.+z))\n",
    "\n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3807312160835836"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova= np.array([np.random.gamma(1.9, 0.65*0.13) for n in range(10000)])\n",
    "\n",
    "np.percentile(prova, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02732035886465833"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12889218044858736"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009670233208198336"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidatedistrGamma(Nsingle,iterations,massoption,SNRth, Tobs, duty):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrNewGamma(Nsingle,it,massoption,SNRth, Tobs, duty))\n",
    "\n",
    "    data=np.array(data)\n",
    "\n",
    "    #[m1,m2,z,pdetLIGO,pdetCE,tmerger,SNR4,SNR10,integralbulk]\n",
    "\n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeventsGamma(bigdata,massoption):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "    Ntot = len(m1) \n",
    "    montecarlo_contributions = integralbulk / Ntot\n",
    "        \n",
    "    return np.sum(montecarlo_contributions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.669906375972902 8.555023530228894\n",
      "7.56036695902468 7.64312226169843\n",
      "7.510186572853788 7.7525176269192\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'EOB',8, 10, 0.75),'EOB'),NeventsGamma(consolidatedistrGamma(10**4,1,'EOB',8,  10, 0.75),'EOB')     \n",
    ")\n",
    "\n",
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'NR',8,  10, 0.75),'NR'),NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8,  10, 0.75),'NR')     \n",
    ")\n",
    "\n",
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'PHEN',8,  10, 0.75),'PHEN'),NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8,  10, 0.75),'PHEN')     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.566863913282771 2.685090915347251\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8, 10, 0.75),'NR'),NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8, 10, 0.75),'NR')     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.608632067395162 2.586479613145505\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8, 6, 0.75),'PHEN'),NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8, 6, 0.75),'PHEN')     \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old sampling, no Gamma function for the rate. Flat distribution in the interval given by the collaboration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrOld(N,iteration,massoption,SNRth, Tobs, duty):\n",
    "    \n",
    "\n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=50*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 0.512\n",
    "    zmin = 0.1\n",
    "    # Largest comoving distance for sampling\n",
    "    #??? dove la usa? -->  cdmax=astropy.cosmology.Planck15.comoving_distance(zmax).value # Mpc\n",
    "    # z pdf normalization. Comoving volume at largest redshift (because comoving volume at z=0 is 0)\n",
    "    # Vczhor = (astropy.cosmology.Planck15.comoving_volume(zmax)/astropy.units.Gpc**3).decompose().value #Gpc^3\n",
    "    # largest merger time (yrs)\n",
    "    tmax = 40\n",
    "    tobs = Tobs\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        #Comoving distance uniform on sphere\n",
    "        #while True:\n",
    "        #    cd = np.sum(np.random.uniform(0, cdmax,3)**2)**0.5\n",
    "        #    if cd<cdmax: break\n",
    "        # Convert to redshift\n",
    "        #z = astropy.cosmology.z_at_value(astropy.cosmology.Planck15.comoving_distance,cd*astropy.units.Mpc )\n",
    "        # Convert to luminosity distance\n",
    "\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = distL(z)\n",
    "\n",
    "        # Mass spectrum\n",
    "        if massoption=='log': # Log flat distribution in both masses\n",
    "            bothm=10**np.random.uniform(np.log10(massmin),np.log10(massmax),2)\n",
    "            m1= max(bothm)\n",
    "            m2= min(bothm)\n",
    "            Rate = 57*10**(-9)\n",
    "        \n",
    "        if massoption == 'EOB':\n",
    "            index = np.random.choice(len(eobdata))\n",
    "            m1 = Msol*eobdata[index][0]\n",
    "            m2 = Msol*eobdata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "        \n",
    "        if massoption == 'PHEN':\n",
    "            index = np.random.choice(len(Phendata))\n",
    "            m1 = Msol* Phendata[index][0]\n",
    "            m2 = Msol*Phendata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "            \n",
    "        if massoption == 'NR':\n",
    "            index = np.random.choice(len(NRdata))\n",
    "            m1 = Msol*NRdata[index][0]\n",
    "            m2 = Msol*NRdata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "            \n",
    "        if massoption == 'breakPL' or massoption == 'breakPLcut':\n",
    "            \n",
    "            sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "            adjusted_index = np.unravel_index(sample_index, mass_ppd[:].shape)\n",
    "            m1 = Msol * mass_1[adjusted_index[1]]\n",
    "            m2 = Msol * mass_1[adjusted_index[1]] * mass_ratio[adjusted_index[0]]\n",
    "            \n",
    "        if massoption == 'PL_error':\n",
    "            index1 = np.random.choice(len(mass_lines['mass_ratio'][:]))\n",
    "            mass_ppd1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )\n",
    "            flat1 = mass_ppd1.flatten() /  np.sum(mass_ppd1.flatten())\n",
    "            \n",
    "            sample_index = np.random.choice(a=flat1.size, p=flat1)\n",
    "            adjusted_index = np.unravel_index(sample_index, mass_ppd1.shape)\n",
    "            m1 = Msol * mass_1[adjusted_index[1]]\n",
    "            m2 = Msol * mass_1[adjusted_index[1]] * mass_ratio[adjusted_index[0]]\n",
    "\n",
    "        \n",
    "        if massoption=='powerlaw': # Power law with spectral index alpha in primary; uniform in secondary\n",
    "            alpha=-2.3\n",
    "            m1 = (massmin**(alpha+1.)+np.random.uniform(0.,1.)*(massmax**(alpha+1.)-massmin**(alpha+1.)))**(1./(alpha+1.))\n",
    "            m2 = np.random.uniform(massmin,m1)\n",
    "            Rate = 0.13*10**(-9)\n",
    "                \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(1*year,41*year)\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr=np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl)\n",
    "\n",
    "\n",
    "        dVcdz = cosmo.comoving_volume(z).value \n",
    "        \n",
    "        if massoption == 'breakPLcut':\n",
    "            \n",
    "            integralbulk = tmax * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * np.heaviside(m1- 45 * Msol,0) * (1./(1.+z))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            integralbulk = tmax * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * (1./(1.+z))\n",
    "\n",
    "            \n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidatedistrOld(Nsingle,iterations,massoption,SNRth, Tobs, duty):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrOld(Nsingle,it,massoption,SNRth, Tobs, duty))\n",
    "\n",
    "    data=np.array(data)\n",
    "\n",
    "    #[m1,m2,z,pdetLIGO,pdetCE,tmerger,SNR4,SNR10,integralbulk]\n",
    "\n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeventsOld(bigdata,massoption,rateinterval):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "\n",
    "    Ntot = len(m1)\n",
    "\n",
    "\n",
    "    # Intrisinc merger rate from LIGO O2 catalog. Use the numbers reported in Sec 4 of 1811.12940, which averages over the two pipelines.\n",
    "    totalrate={}\n",
    "    if massoption=='powerlaw':\n",
    "        totalrate['median'] =  57*10**(-9)\n",
    "        totalrate['upper'] = (57 + 40)*10**(-9)\n",
    "        totalrate['lower'] = (57. - 25.)*10**(-9)\n",
    "    if massoption=='log':\n",
    "        totalrate['median'] = 0.13*10**(-9) #19.*10**(-9)\n",
    "        totalrate['upper'] = (19. + 13.)*10**(-9)\n",
    "        totalrate['lower'] = (19. - 8.2)*10**(-9)\n",
    "        \n",
    "    if massoption=='EOB' or massoption=='NR' or massoption=='PHEN':\n",
    "        totalrate['median'] = 0.13*10**(-9) #19.*10**(-9)\n",
    "        totalrate['upper'] = (0.13 + 0.3)*10**(-9)\n",
    "        totalrate['lower'] = (0.13 - 0.11)*10**(-9)\n",
    "        \n",
    "    if massoption == 'breakPL' or massoption == 'breakPLcut' or 'PL_error':\n",
    "        totalrate['median'] = ratePL *10**(-9)\n",
    "\n",
    "    \n",
    "    montecarlo_contributions = totalrate[rateinterval] * integralbulk / Ntot\n",
    "    \n",
    "\n",
    "    return np.sum(montecarlo_contributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.642078806972979"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'breakPLcut',8, 10, 0.75),'breakPLcut','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.922658073322298"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**5,1,'breakPLcut',8, 10, 0.75),'breakPLcut','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.2690609388038085"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**5,1,'NR',8),'NR','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.98542234659153"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'breakPL',8),'breakPL','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.20017399162604"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'breakPLcut',8),'breakPLcut','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.374568770819394"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**3,1,'PL_error',8),'PL_error','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.84905803448296"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'PL_error',8),'PL_error','median')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsec event rate NR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrOldIntrinsic(N,iteration,SNRth, Tobs, duty, ttmin, ttmax):\n",
    "    \n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=50*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 0.512\n",
    "    zmin = 0.1\n",
    "    # Largest comoving distance for sampling\n",
    "    # largest merger time (yrs)\n",
    "    tmax = ttmax\n",
    "    tobs = Tobs\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        #Comoving distance uniform on sphere\n",
    "        #while True:\n",
    "        #    cd = np.sum(np.random.uniform(0, cdmax,3)**2)**0.5\n",
    "        #    if cd<cdmax: break\n",
    "        # Convert to redshift\n",
    "        #z = astropy.cosmology.z_at_value(astropy.cosmology.Planck15.comoving_distance,cd*astropy.units.Mpc )\n",
    "        # Convert to luminosity distance\n",
    "\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = distL(z)\n",
    "\n",
    "        # Mass spectrum\n",
    "        \n",
    "        index = np.random.choice(len(NRdata))\n",
    "        m1 = Msol*NRdata[index][0]\n",
    "        m2 = Msol*NRdata[index][1]\n",
    "        \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(ttmin*year,tmax*year)\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr=np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl)\n",
    "\n",
    "\n",
    "        dVcdz = cosmo.comoving_volume(z).value \n",
    "        \n",
    "            \n",
    "        integralbulk = (tmax-ttmin) * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * (1./(1.+z))\n",
    "\n",
    "            \n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n",
    "\n",
    "def consolidatedistrIntrinsic(Nsingle,iterations,SNRth, Tobs, duty, ttmin, ttmax):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrOldIntrinsic(Nsingle,iterations,SNRth, Tobs, duty, ttmin, ttmax))\n",
    "\n",
    "    data=np.array(data)\n",
    "    \n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10\n",
    "\n",
    "\n",
    "def NeventsIntrinsic(bigdata):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "\n",
    "    Ntot = len(m1)\n",
    "\n",
    "    montecarlo_contributions = integralbulk / Ntot\n",
    "\n",
    "    return np.sum(montecarlo_contributions) * 1e-9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.39288307862399"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.001,200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.72455947026308"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.76847590478999"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of R and N events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*48.354,1)[0] for n in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "def givePoisson(Nmed):\n",
    "    \n",
    "    arr = np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*Nmed,1)[0] for n in range(10000)])\n",
    "    \n",
    "    return np.median(arr), np.percentile(arr,95)- np.median(arr), np.percentile(arr,5)- np.median(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.0, 11.0, -5.0)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Duty 0.75, 10 obs, Noise 10 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 0.75, 0.001,50))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.0, 8.049999999999272, -3.0)"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Duty 0.7, 6 obs, Noise 10 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 6, 0.75, 0.001,50))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 9.0, -4.0)"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 1, 10 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.0001,50))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 6.0, -2.0)"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 1, 6 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 6, 1, 0.001,50))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.0, 4.0, -2.0)"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 0.75, 6 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 6, 0.75, 0.001,50))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34879400000500027\n"
     ]
    }
   ],
   "source": [
    "t = time.process_time()\n",
    "np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*48.354,1)[0] for n in range(10000)])\n",
    "\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
