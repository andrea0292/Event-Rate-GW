{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import sqrt\n",
    "from numpy import sin\n",
    "from numpy import pi\n",
    "from numpy import cos\n",
    "from numpy import exp\n",
    "from numpy import tanh\n",
    "from numpy import zeros\n",
    "from numpy import arccos\n",
    "from numpy import log10\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.optimize as opt\n",
    "import emcee\n",
    "from pylab import plot\n",
    "from scipy import integrate\n",
    "import corner\n",
    "import random\n",
    "from collections import Counter\n",
    "import time\n",
    "import scipy\n",
    "from scipy.stats import poisson # use as poisson.pmf(number of events , mean value)\n",
    "from scipy import optimize\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import astropy.units as u\n",
    "import astropy.constants as c\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value\n",
    "from tqdm import *\n",
    "from astropy.cosmology import Planck13 as cosmo\n",
    "from astropy import constants as const\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cmasher as cmr\n",
    "import matplotlib.colors as clrs\n",
    "import matplotlib.cm as cmap\n",
    "\n",
    "colors = ['#8a1f1f','#79a43a','#C59D34','#171782', '#cf6717','#ad6faa',\n",
    "          '#009999','#828282']\n",
    "plt.rcParams['axes.prop_cycle'] = plt.cycler(color=colors)\n",
    "plt.rcParams['lines.linewidth'] = 3.0\n",
    "plt.rcParams['axes.linewidth'] = 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some useful quantities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath\n",
    "# we work in geometrized units\n",
    "Msol = 1.47680000000000000000000000000000000 # in km\n",
    "c = 1 # we have actually put them to one everywhere in the code already\n",
    "G = 1\n",
    "year = 60*60*24*(365.250000000000000000000000000); # s\n",
    "cc = 2.9980000000000000000000000000000*10**5 # velocity of light in Km/s\n",
    "pc = 3.0856770000000000000000000000*10**13 # km\n",
    "\n",
    "H0 = 67.9 # km /s / Mpc # changed to PLANCK 2015\n",
    "Omegam = 0.306\n",
    "OmegaL = 0.694\n",
    "Omegar = 0.\n",
    "\n",
    "# some useful functions \n",
    "def distL(z):\n",
    "    return cosmo.luminosity_distance(z).to(u.km).value #(1+z) * integrate.quad(invE,0,z)[0] *cc / H0 *10**6*pc # km\n",
    "\n",
    "def Ez(z):\n",
    "    return sqrt(Omegar*(1+z)**4+Omegam*(1+z)**3+OmegaL)\n",
    "\n",
    "def invE(z):\n",
    "    return 1. / Ez(z)\n",
    "\n",
    "def primopezzo(zp):\n",
    "    return 1/Ez(zp)*(integrate.quad(invE,0,zp)[0])**2\n",
    "\n",
    "def dVdz(z):\n",
    "    return 4*pi*(cc/H0)**3*primopezzo(z) # Mpc**3\n",
    "\n",
    "def dtdf(f,m1,m2):  # Hz, km, km, gravitational wave frequency\n",
    "    return 5/(96*pi**(8/3))*(1./cc*(m1 + m2)*(m1*m2/(m1 + m2)**2)**(3/5))**(-5/\n",
    "  3)*f**(-11/3)  # s^2, assuming f in Hz and m in km\n",
    "\n",
    "def solof(f):\n",
    "    return f**(-11/3)\n",
    "\n",
    "def nu(m1,m2):\n",
    "    return m1*m2/((m1+m2)**2)\n",
    "\n",
    "def Mc(m1,m2):\n",
    "    return (m1 + m2) * (m1*m2/((m1+m2)**2))**(3/5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some other useful functions for frequencies, time of merger, ecc \n",
    "\n",
    "# frequency functions \n",
    "\n",
    "def fMIN2(fmax0,m1,m2,Tobs): # gravitational wave frequency\n",
    "    return 1/(1/fmax0**(8/3)+256/5*(Mc(m1,m2)/cc)**(5/3)*pi**(8/3)*(Tobs))**(3/8)\n",
    "\n",
    "def fmax(m1,m2,fmin,Tobs): # gravitational wave frequency\n",
    "    return fmin*((5*cc)/(5*cc-256*fmin**(8/3)*pi**(8/3)*Tobs*Mc(m1,m2)*(Mc(m1,m2)/cc)**(2/3)))**(3/8)\n",
    "\n",
    "\n",
    "# gives fmax, given fmin and Tobs. If fmax is above 10 Hz, gives 10 Hz instead. frequency is always in Hz\n",
    "\n",
    "def getfmax(m1,m2,fmin,Tobs): # gravitational wave frequency\n",
    "    if fMIN2(1,m1,m2,Tobs)>fmin:\n",
    "        return fmax(m1,m2,fmin,Tobs)\n",
    "    else: \n",
    "        return 1\n",
    "\n",
    "def Tmerger(m1,m2,fmin): # gravitational wave frequency\n",
    "    return 5. * (m1 + m2)**(1./3.) * cc**(5./3.)/ (256. * fmin**(8./3.) * m1 * m2 * np.pi**(8./3.))\n",
    "\n",
    "\n",
    "\n",
    "from scipy.optimize import root_scalar\n",
    "def findFmin(timemerger,m1,m2):\n",
    "    def condition(fmin):\n",
    "        return timemerger-Tmerger(m1,m2,fmin)\n",
    "    return root_scalar(condition,bracket=(10**-4,1)).root\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here we want to add also the part with the SNR \n",
    "\n",
    "# LISA noise parameters\n",
    "Amp = 5/10*18/10*10**-44\n",
    "alpha = 138/1000\n",
    "beta = -221\n",
    "kappa = 521\n",
    "gamma = 1680\n",
    "fk = 113/10**5\n",
    "L0 = 25/10*10**9\n",
    "fstar = 1909/100*10**-3\n",
    "pm = 10**-12\n",
    "\n",
    "skyav=(4/5*sqrt(2)*sin(pi/3))\n",
    "\n",
    "# noise function, checked with Mathematica\n",
    "\n",
    "def Sacc(f):\n",
    "    return (3*10**-15)**2*(1+(4/10*10**-3/f)**2)*(1+(f/(8*10**-3))**4)\n",
    "\n",
    "def Sgal(f):\n",
    "    return Amp*f**(-7/3)*exp(-f**alpha+beta*f*sin(kappa*f))*(1+tanh(gamma*(fk-f)))\n",
    "\n",
    "def Soms(f, d):\n",
    "    return (d *pm)**2*(1+(2*10**-3/f)**4)  # noi: 10\n",
    "\n",
    "def Sacc(f):\n",
    "    return (3*10**-15)**2*(1+(4/10*10**-3/f)**2)*(1+(f/(8*10**-3))**4)\n",
    "    \n",
    "def SnSA(f, d):\n",
    "    return 10/3*(4*Sacc(f)/(2*pi*f)**4+Soms(f, d))/(L0**2)*(1+6/10*(f/fstar)**2)\n",
    "\n",
    "def R(f):\n",
    "    return 3/20*2\n",
    "\n",
    "def Sn(f, d):\n",
    "    return abs(SnSA(f, d)+Sgal(f))\n",
    "\n",
    "def Pn(f, d): # gravitational wave frequency\n",
    "    return abs(Sn(f, d)*R(f))\n",
    "\n",
    "def Aplus(iota,psi):\n",
    "    return -(1+cos(iota)**2)*cos(2*psi)-2*cos(iota)*sin(2*psi)\n",
    "\n",
    "def Across(iota,psi):\n",
    "    return (1+cos(iota)**2)*sin(2*psi)-2*cos(iota)*cos(2*psi)\n",
    "\n",
    "def Fplus(theta,phi):\n",
    "    return 1/2*(1+cos(theta)**2)*cos(2*phi)\n",
    "\n",
    "def Fcross(theta,phi):\n",
    "    return cos(theta)*sin(2*phi)\n",
    "\n",
    "def factorsky(iota,psi,theta,phi):\n",
    "    return Fplus(theta,phi)*Aplus(iota,psi)+1j*Fcross(theta,phi)*Across(iota,psi)\n",
    "\n",
    "def factorskySNR(iota,psi,theta,phi):\n",
    "    return abs(sqrt(2)*sin(pi/3)*(Fplus(theta,phi)*Aplus(iota,psi)+1j*Fcross(theta,phi)*Across(iota,psi)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waveform and SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# waveform\n",
    "\n",
    "def ampl(m1,m2,d): \n",
    "    return (Mc(m1,m2)*G)**(5/6)*sqrt(5/24)/(pi**(2/3)*d*c**(3/2))\n",
    "def habs(m1,m2,d,f): # gravitational wave frequency\n",
    "    return ampl(m1,m2,d)*f**(-7/6)\n",
    "\n",
    "#print(habs(12.4913,12.3884,10.8287*10**6*pc,1./cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we define the SNR; \n",
    "# be careful that I have already put the factor for the sky average\n",
    "# we use the GW only template.\n",
    "\n",
    "def SNR(iota,psi,theta,phi,fmin,fmax,m1,m2,d, leng): # gravitational wave frequency\n",
    "    return 1/2 * sqrt(4*integrate.quad(lambda x: (factorskySNR(iota,psi,theta,phi)*habs(m1,m2,d, x/cc))**2/(Pn(x, leng)*(cc**2)), fmin, fmax)[0])\n",
    "#different noise here!\n",
    "\n",
    "def SNRAverage(fmin,fmax,m1,m2,d, leng): # gravitational wave frequency\n",
    "    return sqrt(4*integrate.quad(lambda x: (skyav*habs(m1,m2,d, x/cc))**2/(Pn(x, leng)*(cc**2)), fmin, fmax)[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.155512461769017\n"
     ]
    }
   ],
   "source": [
    "z = 0.24716227944027847\n",
    "tmerger = 5.073762956477287*year\n",
    "m1 = 88.7\n",
    "m2 = 64.93\n",
    "(iota, psi, theta, phi) = 2.23353428920549, 5.484427462941964, 2.014813251983311, 2.374251372635906\n",
    "fmin = findFmin(tmerger,m1,m2)\n",
    "#print(fmin)\n",
    "tobs = 6.*year\n",
    "fmax= getfmax(m1*(1.+z),m2*(1.+z),fmin/(1+z),tobs)\n",
    "#print(fmax)\n",
    "loSNR=SNR(iota,psi,theta,phi,fmin/(1+z),fmax,m1*(1+z),m2*(1+z),distL(z), 15)\n",
    "print(loSNR) # 6.155,9.07"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "eobdata = np.loadtxt('EOBmasses.dat')\n",
    "NRdata = np.loadtxt('NRmasses.dat')\n",
    "Phendata = np.loadtxt('PHENmasses.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "data = h5py.File('/Users/andreacaputo/Desktop/Phd/BinaryLISALIGO/Event_SamplesWaveTransient/all_events/o1o2o3_mass_c_iid_mag_two_comp_iid_tilt_powerlaw_redshift_mass_data.h5', 'r')\n",
    "mass_ppd = data[\"ppd\"]\n",
    "mass_lines = data[\"lines\"]\n",
    "\n",
    "# Create a flat copy of the array\n",
    "flat = mass_ppd[:].flatten() /  np.sum(mass_ppd[:].flatten())\n",
    "\n",
    " \n",
    "mass_1 = np.linspace(3, 100, 1000)\n",
    "mass_ratio = np.linspace(0.1, 1, 500)\n",
    "\n",
    "ratePL = np.trapz(np.trapz(mass_ppd, mass_ratio, axis=0), mass_1, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_ppd[:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KeysViewHDF5 ['mass_1', 'mass_ratio']>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1000)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines['mass_1'][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5166"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(len(mass_lines['mass_ratio'][:]))\n",
    "try1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )\n",
    "flat = mass_ppd[:].flatten() /  np.sum(mass_ppd[:].flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+000, 0.00000000e+000, 0.00000000e+000, ...,\n",
       "       1.53344045e-110, 7.08344558e-111, 3.26828825e-111])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try1.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "try1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 500)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mass_lines['mass_ratio'][:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "massratioAll = mass_lines['mass_ratio'][:]\n",
    "mass1All = mass_lines['mass_1'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 1000)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.einsum('ij, ik -> jk', massratioAll , mass1All).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$2011.7574 \\; \\mathrm{Mpc}$"
      ],
      "text/plain": [
       "<Quantity 2011.75743363 Mpc>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosmo.comoving_distance(0.52)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrNewGamma(N,iteration,massoption,SNRth, Tobs, duty, leng):\n",
    "    \n",
    "\n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=50*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 1.05\n",
    "    zmin = 0.115\n",
    "    tmax = 41\n",
    "    tmin = 1\n",
    "    tobs = Tobs # in years\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = cosmo.luminosity_distance(z).to(u.km).value\n",
    "        \n",
    "        if massoption == 'EOB':\n",
    "            index = np.random.choice(len(eobdata))\n",
    "            m1 = Msol*eobdata[index][0]\n",
    "            m2 = Msol*eobdata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "        \n",
    "        if massoption == 'PHEN':\n",
    "            index = np.random.choice(len(Phendata))\n",
    "            m1 = Msol* Phendata[index][0]\n",
    "            m2 = Msol*Phendata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "            \n",
    "            \n",
    "        if massoption == 'NR':\n",
    "            index = np.random.choice(len(NRdata))\n",
    "            m1 = Msol*NRdata[index][0]\n",
    "            m2 = Msol*NRdata[index][1]\n",
    "            Rate = 0.13*10**(-9) #19.*10**(-9)\n",
    "                \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(tmin*year,41*year)\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr=np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl, leng)\n",
    "\n",
    "        dVcdz = dVdz(z)\n",
    "        #rateSampling = np.random.gamma(1, 1.46*Rate) #np.random.normal(Rate, 0.3e-9)#1 / np.random.gamma(1, 1/ Rate)\n",
    "        \n",
    "        integralbulk = Rate *  (tmax - tmin) * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * (1./(1.+z))\n",
    "\n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3807312160835836"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prova= np.array([np.random.gamma(1.9, 0.65*0.13) for n in range(10000)])\n",
    "\n",
    "np.percentile(prova, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02732035886465833"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12889218044858736"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(prova)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009670233208198336"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidatedistrGamma(Nsingle,iterations,massoption,SNRth, Tobs, duty, leng):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrNewGamma(Nsingle,it,massoption,SNRth, Tobs, duty, leng))\n",
    "\n",
    "    data=np.array(data)\n",
    "\n",
    "    #[m1,m2,z,pdetLIGO,pdetCE,tmerger,SNR4,SNR10,integralbulk]\n",
    "\n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeventsGamma(bigdata,massoption):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "    Ntot = len(m1) \n",
    "    montecarlo_contributions = integralbulk / Ntot\n",
    "        \n",
    "    return np.sum(montecarlo_contributions)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.669906375972902 8.555023530228894\n",
      "7.56036695902468 7.64312226169843\n",
      "7.510186572853788 7.7525176269192\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'EOB',8, 10, 0.75),'EOB'),NeventsGamma(consolidatedistrGamma(10**4,1,'EOB',8,  10, 0.75),'EOB')     \n",
    ")\n",
    "\n",
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'NR',8,  10, 0.75),'NR'),NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8,  10, 0.75),'NR')     \n",
    ")\n",
    "\n",
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'PHEN',8,  10, 0.75),'PHEN'),NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8,  10, 0.75),'PHEN')     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.566863913282771 2.685090915347251\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8, 10, 0.75),'NR'),NeventsGamma(consolidatedistrGamma(10**4,1,'NR',8, 10, 0.75),'NR')     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.608632067395162 2.586479613145505\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8, 6, 0.75),'PHEN'),NeventsGamma(consolidatedistrGamma(10**4,1,'PHEN',8, 6, 0.75),'PHEN')     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.936926601999076"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsGamma(consolidatedistrGamma(10**5,1,'EOB',8, 10, 0.75, 10),'EOB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.889216665121617\n",
      "3.6196375887883283\n"
     ]
    }
   ],
   "source": [
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'EOB',8, 6, 1, 15),'EOB'))\n",
    "print(NeventsGamma(consolidatedistrGamma(10**5,1,'EOB',8, 6, 0.75, 15),'EOB'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old sampling, no Gamma function for the rate. Flat distribution in the interval given by the collaboration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmax=42*Msol\n",
    "mmin=7.9*Msol\n",
    "alpha=1.6\n",
    "beta=6.7\n",
    "\n",
    "def CCC(m1):\n",
    "    return (mmax**alpha)*(mmin**alpha)*(-1+alpha)*(1+beta)/(mmax**alpha*mmin-mmax*mmin**alpha)/(m1-mmin*(mmin/m1)**beta)\n",
    "\n",
    "def p12(m1,m2): # 1/ km^2\n",
    "    if (mmin<= m2 <= m1 <= mmax ):  #208*Msol/5\n",
    "        return ((m1)**(-alpha)*(m2/m1)**beta)*CCC(m1)  #2/5\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ary_random = np.array([10**np.random.uniform(np.log10(7.9*Msol),np.log10(42*Msol),2) for i in range(10000)])\n",
    "\n",
    "for i in range(len(ary_random)):\n",
    "    if ary_random[i][0] < ary_random[i][1]:\n",
    "        ary_random[i][0], ary_random[i][1] = ary_random[i][1], ary_random[i][0] \n",
    "\n",
    "array_pd = np.array([p12(ary_random[i][0],ary_random[i][1]) for i in range(len(ary_random))])\n",
    "array_pdNorm = array_pd/np.sum(array_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6416"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(a=array_pdNorm.size, p= array_pdNorm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrOld(N,iteration,massoption,SNRth, Tobs, duty, leng):\n",
    "    \n",
    "\n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=5*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 0.512\n",
    "    zmin = 0.\n",
    "    # Largest comoving distance for sampling\n",
    "    #??? dove la usa? -->  cdmax=astropy.cosmology.Planck15.comoving_distance(zmax).value # Mpc\n",
    "    # z pdf normalization. Comoving volume at largest redshift (because comoving volume at z=0 is 0)\n",
    "    # Vczhor = (astropy.cosmology.Planck15.comoving_volume(zmax)/astropy.units.Gpc**3).decompose().value #Gpc^3\n",
    "    # largest merger time (yrs)\n",
    "    tmax = 1e4\n",
    "    tmin = 1e-3\n",
    "    tobs = Tobs\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        #Comoving distance uniform on sphere\n",
    "        #while True:\n",
    "        #    cd = np.sum(np.random.uniform(0, cdmax,3)**2)**0.5\n",
    "        #    if cd<cdmax: break\n",
    "        # Convert to redshift\n",
    "        #z = astropy.cosmology.z_at_value(astropy.cosmology.Planck15.comoving_distance,cd*astropy.units.Mpc )\n",
    "        # Convert to luminosity distance\n",
    "\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = distL(z)\n",
    "\n",
    "        # Mass spectrum\n",
    "        if massoption=='log': # Log flat distribution in both masses\n",
    "            bothm=10**np.random.uniform(np.log10(massmin),np.log10(massmax),2)\n",
    "            m1= max(bothm)\n",
    "            m2= min(bothm)\n",
    "            Rate = 32*10**(-9)\n",
    "            \n",
    "        if massoption == 'our_old':\n",
    "            index = np.random.choice(a=array_pdNorm.size, p= array_pdNorm)\n",
    "            m1 = ary_random[index][0]\n",
    "            m2 = ary_random[index][1]\n",
    "        \n",
    "        if massoption == 'EOB':\n",
    "            index = np.random.choice(len(eobdata))\n",
    "            m1 = Msol*eobdata[index][0]\n",
    "            m2 = Msol*eobdata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "        \n",
    "        if massoption == 'PHEN':\n",
    "            index = np.random.choice(len(Phendata))\n",
    "            m1 = Msol* Phendata[index][0]\n",
    "            m2 = Msol*Phendata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "            \n",
    "        if massoption == 'NR':\n",
    "            index = np.random.choice(len(NRdata))\n",
    "            m1 = Msol*NRdata[index][0]\n",
    "            m2 = Msol*NRdata[index][1]\n",
    "            Rate = 0.13*10**(-9)\n",
    "            \n",
    "        if massoption == 'breakPL' or massoption == 'breakPLcut':\n",
    "            \n",
    "            sample_index = np.random.choice(a=flat.size, p=flat)\n",
    "            adjusted_index = np.unravel_index(sample_index, mass_ppd[:].shape)\n",
    "            m1 = Msol * mass_1[adjusted_index[1]]\n",
    "            m2 = Msol * mass_1[adjusted_index[1]] * mass_ratio[adjusted_index[0]]\n",
    "            \n",
    "        if massoption == 'PL_error':\n",
    "            index1 = np.random.choice(len(mass_lines['mass_ratio'][:]))\n",
    "            mass_ppd1 = np.outer(mass_lines['mass_ratio'][:][5166], mass_lines['mass_1'][:][5166] )\n",
    "            flat1 = mass_ppd1.flatten() /  np.sum(mass_ppd1.flatten())\n",
    "            \n",
    "            sample_index = np.random.choice(a=flat1.size, p=flat1)\n",
    "            adjusted_index = np.unravel_index(sample_index, mass_ppd1.shape)\n",
    "            m1 = Msol * mass_1[adjusted_index[1]]\n",
    "            m2 = Msol * mass_1[adjusted_index[1]] * mass_ratio[adjusted_index[0]]\n",
    "\n",
    "        \n",
    "        if massoption=='powerlaw' or massoption=='powerlaw2': # Power law with spectral index alpha in primary; uniform in secondary\n",
    "            alpha=-2.35\n",
    "            m1 = (massmin**(alpha+1.)+np.random.uniform(0.,1.)*(massmax**(alpha+1.)-massmin**(alpha+1.)))**(1./(alpha+1.))\n",
    "            m2 = np.random.uniform(massmin,m1)\n",
    "            Rate = 103*10**(-9)\n",
    "                \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(tmin*year,tmax*year)\n",
    "        \n",
    "        if tmerger > 100*year:\n",
    "            soglia = 10\n",
    "        else:\n",
    "            soglia = SNRth\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr= np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl, leng)\n",
    "\n",
    "\n",
    "        dVcdz = cosmo.comoving_volume(z).value \n",
    "        \n",
    "        if massoption == 'breakPLcut':\n",
    "            \n",
    "            integralbulk = (tmax - tmin) * (zmax-zmin) * dVcdz   *np.heaviside(snr-soglia,0) * np.heaviside(m1- 45 * Msol,0) * (1./(1.+z))\n",
    "\n",
    "        else:\n",
    "            \n",
    "            integralbulk = (tmax - tmin) * (zmax-zmin) * dVcdz   *np.heaviside(snr-soglia,0) * (1./(1.+z))\n",
    "\n",
    "            \n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def consolidatedistrOld(Nsingle,iterations,massoption,SNRth, Tobs, duty, leng):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrOld(Nsingle,it,massoption,SNRth, Tobs, duty, leng))\n",
    "\n",
    "    data=np.array(data)\n",
    "\n",
    "    #[m1,m2,z,pdetLIGO,pdetCE,tmerger,SNR4,SNR10,integralbulk]\n",
    "\n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NeventsOld(bigdata,massoption,rateinterval):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "\n",
    "    Ntot = len(m1)\n",
    "\n",
    "\n",
    "    # Intrisinc merger rate from LIGO O2 catalog. Use the numbers reported in Sec 4 of 1811.12940, which averages over the two pipelines.\n",
    "    totalrate={}\n",
    "    if massoption=='powerlaw':\n",
    "        totalrate['median'] =  103*10**(-9)\n",
    "        totalrate['upper'] = (57 + 40)*10**(-9)\n",
    "        totalrate['lower'] = (57. - 25.)*10**(-9)\n",
    "    \n",
    "    if massoption=='powerlaw2':\n",
    "        totalrate['median'] =  53*10**(-9)\n",
    "        totalrate['upper'] = (53 + 40)*10**(-9)\n",
    "        totalrate['lower'] = (53. - 25.)*10**(-9)\n",
    "    \n",
    "    if massoption=='log':\n",
    "        totalrate['median'] = 32*10**(-9) #19.*10**(-9)\n",
    "        totalrate['upper'] = (19. + 13.)*10**(-9)\n",
    "        totalrate['lower'] = (19. - 8.2)*10**(-9)\n",
    "        \n",
    "    if massoption=='EOB' or massoption=='NR' or massoption=='PHEN':\n",
    "        totalrate['median'] = 0.13*10**(-9) #19.*10**(-9)\n",
    "        totalrate['upper'] = (0.13 + 0.3)*10**(-9)\n",
    "        totalrate['lower'] = (0.13 - 0.11)*10**(-9)\n",
    "        \n",
    "    if massoption == 'breakPL' or massoption == 'breakPLcut' or 'PL_error':\n",
    "        totalrate['median'] = 53*10**(-9) #ratePL *10**(-9)\n",
    "        \n",
    "    if massoption == 'our_old':\n",
    "        totalrate['median'] = 53*10**(-9) #ratePL *10**(-9)\n",
    "\n",
    "    \n",
    "    montecarlo_contributions = totalrate[rateinterval] * integralbulk / Ntot\n",
    "    \n",
    "\n",
    "    return np.sum(montecarlo_contributions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6023772916139165"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'our_old',15, 10, 1, 10),'our_old','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111.30854970754262"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**6,1,'log',15, 10, 1, 10),'log','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.572428603701008"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**5,1,'powerlaw',15, 10, 1, 10),'powerlaw','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.79138778289758"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**3,1,'breakPL',15, 10, 1, 10),'breakPL','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.628436065541244"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsOld(consolidatedistrOld(10**4,1,'breakPLcut',8, 10, 1, 10),'breakPLcut','median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intrinsec event rate NR "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gendistrOldIntrinsic(N,iteration,SNRth, Tobs, duty, ttmin, ttmax, leng):\n",
    "    \n",
    "    N=int(N)\n",
    "    # Define functions to store intermediate products; I haven't decided on the most convenient format for the final catalogs yet...\n",
    "\n",
    "    massmin=50*Msol\n",
    "    massmax=100*Msol\n",
    "\n",
    "    # Largest horizon redshift; don't waste computing time above this\n",
    "    zmax = 0.512\n",
    "    zmin = 0.\n",
    "    # Largest comoving distance for sampling\n",
    "    # largest merger time (yrs)\n",
    "    tmax = ttmax\n",
    "    tobs = Tobs\n",
    "    # ground-based duty cycle\n",
    "    dutycycle= duty\n",
    "\n",
    "    data=[]\n",
    "    for i in range(N):\n",
    "\n",
    "        #Comoving distance uniform on sphere\n",
    "        #while True:\n",
    "        #    cd = np.sum(np.random.uniform(0, cdmax,3)**2)**0.5\n",
    "        #    if cd<cdmax: break\n",
    "        # Convert to redshift\n",
    "        #z = astropy.cosmology.z_at_value(astropy.cosmology.Planck15.comoving_distance,cd*astropy.units.Mpc )\n",
    "        # Convert to luminosity distance\n",
    "\n",
    "        z = np.random.uniform(zmin,zmax)\n",
    "        dl = cosmo.luminosity_distance(z).to(u.km).value\n",
    "\n",
    "        # Mass spectrum\n",
    "        \n",
    "        index = np.random.choice(len(NRdata))\n",
    "        m1 = Msol*NRdata[index][0]\n",
    "        m2 = Msol*NRdata[index][1]\n",
    "        \n",
    "        # Sky-location, inclination, polarization, initial phase\n",
    "        cosiota = random.uniform(-1.,1.)\n",
    "        psi = random.uniform(0,2*pi)\n",
    "        costheta=random.uniform(-1.,1.)\n",
    "        phi=random.uniform(0,2*pi)\n",
    "        iota=np.arccos(cosiota)\n",
    "        theta=np.arccos(costheta)\n",
    "        #phic = np.random.uniform(0,2.*np.pi)\n",
    "        \n",
    "        # Merger time\n",
    "        tmerger=np.random.uniform(ttmin*year,tmax*year)\n",
    "        \n",
    "        #fmin=np.random.uniform(1e-5,0.01)\n",
    "        fmin=findFmin(tmerger,m1,m2)\n",
    "        Fmax= getfmax(m1*(1+z),m2*(1+z),fmin/(1+z),tobs*year)  #fmax(m1,m2,fmin,tobs*year)\n",
    "        #Fmax = 1 #Fmax=1\n",
    "        snr=np.sqrt(dutycycle)*SNR(iota,psi,theta,phi,fmin/(1+z),Fmax,m1*(1+z),m2*(1+z),dl, leng)\n",
    "\n",
    "\n",
    "        dVcdz = dVdz(z) \n",
    "        \n",
    "            \n",
    "        integralbulk = (tmax-ttmin) * (zmax-zmin) * dVcdz   *np.heaviside(snr-SNRth,0) * (1./(1.+z))\n",
    "\n",
    "            \n",
    "        data.append(np.array([m1,m2,z,fmin,integralbulk,snr]))\n",
    "\n",
    "    return np.array(data).T\n",
    "\n",
    "def consolidatedistrIntrinsic(Nsingle,iterations,SNRth, Tobs, duty, ttmin, ttmax, leng):\n",
    "\n",
    "    Nsingle = int(Nsingle)\n",
    "    iterations = int(iterations)\n",
    "\n",
    "    Ntot = Nsingle*iterations\n",
    "    data=[]\n",
    "    for it in range(0,iterations):\n",
    "        data.append(gendistrOldIntrinsic(Nsingle,iterations,SNRth, Tobs, duty, ttmin, ttmax, leng))\n",
    "\n",
    "    data=np.array(data)\n",
    "    \n",
    "    m1 = np.concatenate(data[:,0])\n",
    "    m2 = np.concatenate(data[:,1])\n",
    "    z = np.concatenate(data[:,2])\n",
    "    #pdetLIGO = np.concatenate(data[:,3])\n",
    "    #pdetCE = np.concatenate(data[:,4])\n",
    "    #tmerger = np.concatenate(data[:,3])\n",
    "    fmin = np.concatenate(data[:,3])\n",
    "    #SNR4 = np.concatenate(data[:,6])\n",
    "    #SNR10 = np.concatenate(data[:,7])\n",
    "    integralbulk = np.concatenate(data[:,4])\n",
    "    SNR10 = np.concatenate(data[:,5])\n",
    "\n",
    "    return m1,m2,z,fmin,integralbulk,SNR10\n",
    "\n",
    "\n",
    "def NeventsIntrinsic(bigdata):\n",
    "\n",
    "    # bigdata is the output of consolidatedistr\n",
    "    m1,m2,z,fmin,integralbulk,SNR10 = bigdata #consolidatedistr(Nsingle,iterations)\n",
    "\n",
    "    Ntot = len(m1)\n",
    "\n",
    "    montecarlo_contributions = integralbulk / Ntot\n",
    "\n",
    "    return np.sum(montecarlo_contributions) * 1e-9\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139.60758272979214"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.001, 1000, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.72455947026308"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.1, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.76847590478999"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeventsIntrinsic(consolidatedistrIntrinsic(10**4,1,8, 10, 1, 0.1, 60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample of R and N events "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova = np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*48.354,1)[0] for n in range(100000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova2 = np.array([np.random.poisson(np.array([np.random.gamma(2, 0.596*0.13)*48.354 for n in range(1000)])) for m in range(100)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "prova3 = prova2.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova3, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(prova, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def givePoisson(Nmed):\n",
    "    \n",
    "    arr = np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*Nmed,1)[0] for n in range(10000)])\n",
    "    \n",
    "    return np.median(arr), np.percentile(arr,95)- np.median(arr), np.percentile(arr,5)- np.median(arr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23.0, 43.0, -19.0)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Duty 1, 10 obs, Noise 10 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 10,1 , 0.001,100, 10))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17.0, 32.0, -14.0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Duty 0.75, 10 obs, Noise 10 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 10, 0.75, 0.001,100, 10))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9.0, 18.0, -8.0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Start with Duty 0.7, 6 obs, Noise 10 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 6, 0.75, 0.001, 100, 10))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11.0, 23.0, -9.0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 1, 10 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 10, 1, 0.0001,100, 15))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13.0, 25.0, -11.0)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 1, 6 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 6, 1, 0.001,100, 10))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.0, 9.0, -4.0)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Duty 0.75, 6 obs, Noise 15 pm\n",
    "\n",
    "NmedToUse = NeventsIntrinsic(consolidatedistrIntrinsic(10**5,1,8, 6, 0.75, 0.001,100, 15))\n",
    "\n",
    "givePoisson(NmedToUse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34879400000500027\n"
     ]
    }
   ],
   "source": [
    "t = time.process_time()\n",
    "np.array([np.random.poisson(np.random.gamma(2, 0.596*0.13)*48.354,1)[0] for n in range(10000)])\n",
    "\n",
    "elapsed_time = time.process_time() - t\n",
    "print(elapsed_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
